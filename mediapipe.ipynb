{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bbdc15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12273baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fight_datapath = './indoor/'\n",
    "fight_train_video_names = pd.read_csv('./fight_train_video_names_list.csv')['names'].to_list()\n",
    "fight_val_video_names = pd.read_csv('./fight_val_video_names_list.csv')['names'].to_list()\n",
    "fight_train_xml_names = os.listdir(fight_datapath+'Training'+'/02.라벨링데이터')\n",
    "fight_val_xml_names = os.listdir(fight_datapath+'Validation'+'/02.라벨링데이터')\n",
    "\n",
    "normal_datapath = './indoor_normal/'\n",
    "normal_train_video_names = os.listdir(normal_datapath+'Training'+'/01.원천데이터')\n",
    "normal_val_video_names = os.listdir(normal_datapath+'Validation'+'/01.원천데이터')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ecd579",
   "metadata": {},
   "outputs": [],
   "source": [
    "fight_train_video_names = list(map(lambda x:'./indoor/Training/01.원천데이터/'+x, fight_train_video_names))\n",
    "fight_val_video_names = list(map(lambda x:'./indoor/Training/01.원천데이터/'+x, fight_val_video_names))\n",
    "normal_train_video_names = list(map(lambda x:'./indoor_normal/Training/01.원천데이터/'+x, normal_train_video_names))\n",
    "normal_val_video_names = list(map(lambda x:'./indoor_normal/Training/01.원천데이터/'+x, normal_val_video_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4b0bebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1752110478.286128  804359 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1752110478.307963  804707 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.127.05), renderer: NVIDIA RTX A6000/PCIe/SSE2\n",
      "W0000 00:00:1752110478.384686  804720 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752110478.433520  804729 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# 경로 설정\n",
    "video_path = fight_train_video_names[0]  # <- 사용자의 영상 경로\n",
    "model_path = \"pose_landmarker_full.task\"  # <- .task 파일 다운로드 필요\n",
    "\n",
    "# 모델 옵션 구성\n",
    "options = vision.PoseLandmarkerOptions(\n",
    "    base_options=python.BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=vision.RunningMode.VIDEO\n",
    ")\n",
    "landmarker = vision.PoseLandmarker.create_from_options(options)\n",
    "\n",
    "# 비디오 열기\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = 3  # 3 FPS 기준\n",
    "frame_interval = int(cap.get(cv2.CAP_PROP_FPS) // fps)\n",
    "frame_index = 0\n",
    "pose_results = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    if frame_index % frame_interval != 0:\n",
    "        frame_index += 1\n",
    "        continue\n",
    "\n",
    "    # 전처리\n",
    "    frame = cv2.resize(frame, (640, 360))\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "\n",
    "    # 타임스탬프 (ms)\n",
    "    timestamp_ms = int(frame_index * (1000 / fps))\n",
    "\n",
    "    # 추론\n",
    "    result = landmarker.detect_for_video(mp_image, timestamp_ms)\n",
    "\n",
    "    # 추출\n",
    "    frame_landmarks = []\n",
    "    if result.pose_landmarks:\n",
    "        for lm in result.pose_landmarks[0]:\n",
    "            frame_landmarks.extend([lm.x, lm.y, lm.visibility])\n",
    "    else:\n",
    "        frame_landmarks = [0.0] * (33 * 3)\n",
    "\n",
    "    pose_results.append([frame_index] + frame_landmarks)\n",
    "    frame_index += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# 컬럼명 설정\n",
    "columns = ['frame']\n",
    "for i in range(33):\n",
    "    columns.extend([f\"x_{i}\", f\"y_{i}\", f\"vis_{i}\"])\n",
    "\n",
    "# 저장\n",
    "df = pd.DataFrame(pose_results, columns=columns)\n",
    "df.to_csv(\"pose_results_3fps.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e125fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "marks = pd.read_csv('./pose_results_3fps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75ed67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. 시각화 유틸\n",
    "# mp_pose = mp.solutions.pose\n",
    "# connections = mp_pose.POSE_CONNECTIONS  # 스켈레톤 연결 정보\n",
    "# landmark_names = [lm.name for lm in mp_pose.PoseLandmark]\n",
    "\n",
    "# # 원본 프레임 불러오기\n",
    "# cap = cv2.VideoCapture(video_path)\n",
    "# ret, frame = cap.read()\n",
    "# h, w, _ = frame.shape\n",
    "\n",
    "# # 3. 시각화 수행\n",
    "# for i, lm in enumerate(marks):\n",
    "#     cx, cy = int(lm['x'] * w), int(lm['y'] * h)\n",
    "#     cv2.circle(frame, (cx, cy), 4, (0, 255, 0), -1)\n",
    "#     cv2.putText(frame, landmark_names[i], (cx + 4, cy - 4),\n",
    "#                 cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "# # 연결선 그리기\n",
    "# for start_idx, end_idx in connections:\n",
    "#     pt1 = marks[start_idx]\n",
    "#     pt2 = marks[end_idx]\n",
    "#     x1, y1 = int(pt1['x'] * w), int(pt1['y'] * h)\n",
    "#     x2, y2 = int(pt2['x'] * w), int(pt2['y'] * h)\n",
    "#     cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 255), 2)\n",
    "\n",
    "# # 4. 결과 보기 (Jupyter에서는 matplotlib 사용)\n",
    "# frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.imshow(frame_rgb)\n",
    "# plt.axis('off')\n",
    "# plt.title(\"Skeleton Only Visualization\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "279514a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyPointstoCSV(video_path, save_path):\n",
    "    # 경로 설정\n",
    "    model_path = \"pose_landmarker_full.task\"  # <- .task 파일 다운로드 필요\n",
    "\n",
    "    # 모델 옵션 구성\n",
    "    options = vision.PoseLandmarkerOptions(\n",
    "        base_options=python.BaseOptions(model_asset_path=model_path),\n",
    "        running_mode=vision.RunningMode.VIDEO\n",
    "    )\n",
    "    landmarker = vision.PoseLandmarker.create_from_options(options)\n",
    "\n",
    "    # 비디오 열기\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = 3  # 3 FPS 기준\n",
    "    frame_interval = int(cap.get(cv2.CAP_PROP_FPS) // fps)\n",
    "    frame_index = 0\n",
    "    pose_results = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_index % frame_interval != 0:\n",
    "            frame_index += 1\n",
    "            continue\n",
    "\n",
    "        # 전처리\n",
    "        frame = cv2.resize(frame, (640, 360))\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "\n",
    "        # 타임스탬프 (ms)\n",
    "        timestamp_ms = int(frame_index * (1000 / fps))\n",
    "\n",
    "        # 추론\n",
    "        result = landmarker.detect_for_video(mp_image, timestamp_ms)\n",
    "\n",
    "        # 추출\n",
    "        frame_landmarks = []\n",
    "        if result.pose_landmarks:\n",
    "            for lm in result.pose_landmarks[0]:\n",
    "                frame_landmarks.extend([lm.x, lm.y, lm.visibility])\n",
    "        else:\n",
    "            frame_landmarks = [0.0] * (33 * 3)\n",
    "\n",
    "        pose_results.append([frame_index] + frame_landmarks)\n",
    "        frame_index += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # 컬럼명 설정\n",
    "    columns = ['frame']\n",
    "    for i in range(33):\n",
    "        columns.extend([f\"x_{i}\", f\"y_{i}\", f\"vis_{i}\"])\n",
    "\n",
    "    # 저장\n",
    "    df = pd.DataFrame(pose_results, columns=columns)\n",
    "    filename = video_path.split('/')[-1]\n",
    "    df.to_csv(f\"{save_path}/{filename}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d7898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1752110489.478163  804359 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1752110489.498725  804897 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.127.05), renderer: NVIDIA RTX A6000/PCIe/SSE2\n",
      "W0000 00:00:1752110489.562249  804910 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752110489.602260  804912 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752110532.384996  804359 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1752110532.407483  805073 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.127.05), renderer: NVIDIA RTX A6000/PCIe/SSE2\n",
      "W0000 00:00:1752110532.480636  805086 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752110532.528504  805092 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752110582.456071  804359 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1752110582.479144  805258 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.127.05), renderer: NVIDIA RTX A6000/PCIe/SSE2\n",
      "W0000 00:00:1752110582.543693  805271 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752110582.602030  805282 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752110629.236095  804359 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1752110629.258390  805489 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.127.05), renderer: NVIDIA RTX A6000/PCIe/SSE2\n",
      "W0000 00:00:1752110629.316959  805501 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752110629.350572  805506 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752110670.931855  804359 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1752110670.970601  805749 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.127.05), renderer: NVIDIA RTX A6000/PCIe/SSE2\n",
      "W0000 00:00:1752110671.032890  805762 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752110671.077381  805764 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752110731.764673  804359 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1752110731.786714  806004 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.127.05), renderer: NVIDIA RTX A6000/PCIe/SSE2\n",
      "W0000 00:00:1752110731.850397  806011 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752110731.890035  806024 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752110776.948478  804359 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1752110776.970781  806175 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.127.05), renderer: NVIDIA RTX A6000/PCIe/SSE2\n",
      "W0000 00:00:1752110777.047425  806187 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752110777.085620  806196 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752110815.431276  804359 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1752110815.447786  806344 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.127.05), renderer: NVIDIA RTX A6000/PCIe/SSE2\n",
      "W0000 00:00:1752110815.519674  806354 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752110815.562384  806360 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752110866.010742  804359 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1752110866.032141  806437 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.127.05), renderer: NVIDIA RTX A6000/PCIe/SSE2\n",
      "W0000 00:00:1752110866.096129  806441 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752110866.127742  806459 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752110909.352094  804359 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1752110909.374535  806609 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.127.05), renderer: NVIDIA RTX A6000/PCIe/SSE2\n",
      "W0000 00:00:1752110909.435814  806613 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752110909.480615  806633 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752110959.655306  804359 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1752110959.677911  806863 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.127.05), renderer: NVIDIA RTX A6000/PCIe/SSE2\n",
      "W0000 00:00:1752110959.742087  806864 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752110959.784004  806887 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752111011.706449  804359 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1752111011.729710  807042 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.127.05), renderer: NVIDIA RTX A6000/PCIe/SSE2\n",
      "W0000 00:00:1752111011.793959  807044 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752111011.835835  807058 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1752111062.372583  804359 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1752111062.395451  807215 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 550.127.05), renderer: NVIDIA RTX A6000/PCIe/SSE2\n",
      "W0000 00:00:1752111062.454881  807228 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752111062.499443  807231 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "for video in normal_train_video_names:\n",
    "    if video.endswith('.mp4'):\n",
    "        keyPointstoCSV(video, './pointsCSV/train/normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12829d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in normal_val_video_names:\n",
    "    if video.endswith('.mp4'):\n",
    "        keyPointstoCSV(video, './pointsCSV/val/normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd5d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in fight_train_video_names:\n",
    "    if video.endswith('.mp4'):\n",
    "        keyPointstoCSV(video, './pointsCSV/train/fight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2276c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in fight_val_video_names:\n",
    "    if video.endswith('.mp4'):\n",
    "        keyPointstoCSV(video, './pointsCSV/val/fight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "won",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
